import streamlit as st
import pdfplumber
import os
from utils.api import DeepSeek_Vendors
from utils.logger import info_logger, filter
import config


DS_Vendor_V0 = DeepSeek_Vendors(config.qwen_configs['api_key'], config.qwen_configs['base_url'])
lls_model = config.qwen_configs['model_name']

Change_Task_Agent = """ä½ ç°åœ¨æ˜¯ä¸€åèµ„æ·±çš„ä¿¡æ¯æ£€æŸ¥å‘˜ï¼Œä½ çš„ç›®æ ‡æ˜¯ç»“åˆæä¾›çš„ä»»åŠ¡æ¸…å•ï¼Œæ£€æŸ¥ç”¨æˆ·è¾“å…¥çš„ä»»åŠ¡æ˜¯å¦ç¬¦åˆè¦æ±‚ã€‚
è¯·æ³¨æ„ï¼Œä½ éœ€è¦æ ¹æ®ä»»åŠ¡æ¸…å•ä¸­çš„è¦æ±‚ï¼Œé€æ¡æ£€æŸ¥ç”¨æˆ·è¾“å…¥çš„ä»»åŠ¡ï¼Œå¹¶ç»™å‡ºè¯¦ç»†çš„åé¦ˆå’Œå»ºè®®ã€‚ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ ¼å¼æ¥ç»„ç»‡ä½ çš„å›ç­”ï¼š
1. ä»»åŠ¡æè¿°ï¼š<ç”¨æˆ·è¾“å…¥çš„ä»»åŠ¡>
2. æ£€æŸ¥ç»“æœï¼š<æ£€æŸ¥ç»“æœ>
3. åé¦ˆå’Œå»ºè®®ï¼š<é’ˆå¯¹æ¯ä¸€æ¡è¦æ±‚çš„åé¦ˆå’Œå»ºè®®>
ä»»åŠ¡æ£€æŸ¥ç»“æœå¯èƒ½æŒ‰ç…§ä»¥ä¸‹æƒ…å†µè¿›è¡Œåˆ†ç±»ï¼š ç¬¦åˆè¦æ±‚ï¼Œè­¦å‘Šï¼Œä¸¥é‡è­¦å‘Šï¼Œæ‹’ç»ã€‚
è¯·ç¡®ä¿ä½ çš„å›ç­”æ¸…æ™°ã€ç®€æ´ï¼Œå¹¶ä¸”åŒ…å«æ‰€æœ‰å¿…è¦çš„ä¿¡æ¯ã€‚ä½ å¯ä»¥ä½¿ç”¨åˆ—è¡¨æˆ–æ®µè½çš„å½¢å¼æ¥ç»„ç»‡ä½ çš„å›ç­”ã€‚
ä»»åŠ¡æ¸…å•å¦‚ä¸‹:{}
å½“å‰ç”¨æˆ·è¾“å…¥ä»»åŠ¡æ˜¯:{}
 """

## ä¸šåŠ¡æµç¨‹çš„æ¢³ç†
## æ·»åŠ æ—¥å¿—ä¿¡æ¯

def read_pdf_pdfplumber(file_path):
	with pdfplumber.open(file_path) as pdf:
		text = []
		for page in pdf.pages:
			text.append(page.extract_text())
			# æå–è¡¨æ ¼ï¼ˆå¦‚æœæœ‰ï¼‰
			tables = page.extract_tables()
			for table in tables:
				print("å‘ç°è¡¨æ ¼:", table)
				## å¤„ç†è¡¨æ ¼æ•°æ®

		return "\n".join(text)

def parser_file(uploaded_file):
	"""
	æ–‡ä»¶è§£ææ¥å£
	å‚æ•°: uploaded_file - ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
	è¿”å›: è§£æç»“æœ
	"""
	# è¿™é‡Œæ›¿æ¢ä¸ºå®é™…çš„æ–‡ä»¶è§£æé€»è¾‘
	if uploaded_file is not None:
		# è¯»å–æ–‡ä»¶å†…å®¹
		print(f"æ­£åœ¨è§£ææ–‡ä»¶: {uploaded_file}")
		info_logger.info(f"æ­£åœ¨è§£ææ–‡ä»¶: {uploaded_file}")
		content = read_pdf_pdfplumber(uploaded_file)
		st.success(f"{uploaded_file.name}æ–‡ä»¶è§£ææˆåŠŸï¼")
		return content
	else:
		# å¦‚æœæ²¡æœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œè¿”å›æç¤ºä¿¡æ¯
		st.warning("æ–‡ä»¶ä¸ºç©ºï¼Œè¯·é‡æ–°ä¸Šä¼ ï¼")

	return None

def response_generator(stream):
	full_response = ""
	try:
		for chunk in stream:
			try:
				if chunk is None:  # ç©ºæ•°æ®åŒ…å¤„ç†
					continue
				chunk_str = str(chunk).strip()
				if chunk_str:
					full_response += chunk_str
					yield chunk_str + "â–Œ"
			except Exception as chunk_error:
				st.warning(f"æ•°æ®å—å¤„ç†å¼‚å¸¸: {str(chunk_error)}")
		yield full_response  # æœ€ç»ˆè¿”å›å®Œæ•´ç»“æœ
	except GeneratorExit:  # ç”Ÿæˆå™¨è¢«å¤–éƒ¨å…³é—­
		st.warning("æµå¼å“åº”è¢«å¼ºåˆ¶ç»ˆæ­¢")
	except Exception as gen_error:
		st.error(f"ç”Ÿæˆå™¨å†…éƒ¨é”™è¯¯: {str(gen_error)}")
		yield "[ERROR] å“åº”ç”Ÿæˆä¸­æ–­"


def check_task(text, context):
	context = context or "æ— å‚è€ƒæ–‡æ¡£"
	prompt = Change_Task_Agent.format(context, text)
	messages = [{"role": "user", "content": prompt}]
	stream = DS_Vendor_V0.chat_stream(messages, lls_model)
	
	try:
		# åˆ›å»ºæ¶ˆæ¯å®¹å™¨
		message_placeholder = st.empty()
		with st.chat_message("assistant", avatar="ğŸ¤–"):
			response_placeholder = st.empty()
			
		# æµå¼è¾“å‡ºé€»è¾‘
		full_response = ""
		for chunk in stream:
			full_response += chunk
			response_placeholder.markdown(full_response + "â–Œ")
			
		# æœ€ç»ˆæ˜¾ç¤ºå®Œæ•´å“åº”
		response_placeholder.markdown(full_response)
		info_logger.info(f"åŠ©æ‰‹å“åº”: {full_response}")
		return full_response
		
	except Exception as e:
		st.error(f"å¤„ç†é”™è¯¯: {str(e)}")
		return None

		
def main():
	st.title("Change Task Aagent")
	
	# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
	if "messages" not in st.session_state:
		st.session_state.messages = []

	# æ˜¾ç¤ºå†å²æ¶ˆæ¯
	for message in st.session_state.messages:
		with st.chat_message(message["role"], avatar=message.get("avatar")):
			st.markdown(message["content"])

	# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
	with st.sidebar:
		uploaded_file = st.file_uploader("ğŸ“ upload task file", type=['pdf'])
		parse_result = parser_file(uploaded_file) if uploaded_file else None
		if parse_result:
			info_logger.info(f"æ–‡ä»¶è§£ææˆåŠŸ: {parse_result}")
		# else:
		# 	st.warning("è¯·ä¸Šä¼ æœ‰æ•ˆçš„æ–‡ä»¶ï¼")

	# ä¸»è¾“å…¥åŒºåŸŸ
	if prompt := st.chat_input("è¯·è¾“å…¥æ£€æŸ¥å†…å®¹:"):
		# è®°å½•ç”¨æˆ·è¾“å…¥
		st.session_state.messages.append({"role": "user", "content": prompt})
		info_logger.info(f"ç”¨æˆ·è¾“å…¥: {prompt}")
		with st.chat_message("user"):
			st.markdown(prompt)

		# æ‰§è¡Œæ£€æŸ¥
		if parse_result:
			with st.status("ğŸ“Š æ­£åœ¨åˆ†ææ–‡æ¡£...", expanded=True) as status:
				response = check_task(prompt, parse_result)
				status.update(label="åˆ†æå®Œæˆ", state="complete", expanded=False)
		else:
			response = check_task(prompt, "æ— å‚è€ƒæ–‡æ¡£")

		# è®°å½•åŠ©æ‰‹å“åº”
		if response:
			st.session_state.messages.append({
				"role": "assistant",
				"content": response,
				"avatar": "ğŸ¤–"
			})

if __name__ == "__main__":
	main()